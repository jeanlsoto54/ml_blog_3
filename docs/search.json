[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jean Luis Soto’s Portfolio",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 4, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\ndelivery app orders prediction\n\n\n\n\n\n\n\nclassification\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2023\n\n\nJean Luis Soto\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/ml/2023-12-19-delivery-app.html",
    "href": "posts/ml/2023-12-19-delivery-app.html",
    "title": "delivery app orders prediction",
    "section": "",
    "text": "# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Displaying at least 50 columns\npd.set_option('display.max_columns',50)\n\n\n# Load data file\ndf = pd.read_csv('DETALLE ORDENES CANCELADAS_CL.csv')\ndf1 = pd.read_csv('DETALLE ORDENES CANCELADAS_EC.csv')\ndf2 = pd.read_csv('DETALLE ORDENES CANCELADAS_PE.csv')\n\n\n#Merging the datasets for the three countries Chile, Ecuador and Peru\nmerged_df = pd.concat([df, df1, df2], axis=0, ignore_index=True)\ndf = merged_df\n\nIt is being upleaded the dataset in 3 batches. each file contains the data of courier orders for the major cities of Perù, Chile and Ecuador\nThe dataset is composed from the next variables:\nCOUNTRY: Origin of the order (CL:chile,EC:ecuador,PE:peru)\nMZ_NAME: microzone of a city defined by the company where it ,mostly all the time, the store and the user.\nDATE_AGG: Date of the order\nDIA_NOMBRE: label of the day when the order happened\nREPURCHASE: Indicades, whether the order had no trackback (previous order for the same user the cancelled and order again in about 1 hour)‘With repurchase’ or not ‘Without repurchase’\nORDER_ID: code of the order\nUSER_TOTAL_ORDERS: counting of how many orders the user previously did\n% COMPLETED: % of the orders that were delivered to the client.\nPAYMENT_METHOD: method to pay the order.\nGMV_USD: net value of the order\nITEM_COUNT: number of items that compose the market basket\nCITY:\nBRAND_NAME:\nSTORE_ID:\nLNG:\nLAT\nT03_PRE_PICKING_TIME: Lead time that is about between the order being set and that the clerk starts to pick up the products.\nT04_PICKING_TIME: time that the clerk takes to gather all the items of the order\nT05_CASHIER_TIME: Time take by the cahier to generate the bill\nT06_REQUESTING_RT_TIME: Time that the clerk takes to ask for a courier to pick up the basket.\nT07_WAITING_RT_TIME: interval of time between the requested call for a courier and the arrivel of it.\nT08_CHECKOUT_TIME: Time that takes that the courier to put the basket on the vehicle\nVEHICLE_TYPE: Type of vehicle thatthe couries has\nMALL: Indicates if the the store is located on a shopping mall\nSUB_VERTICAL: Classification defined by the company for the store (Supermarket, pharmacy and so on)\nDISTANCE_KM: Distance between the store and the user\nTAG_GLOBAL_OFFER: Boolean that indicades if the order had a discount or not.\nSTOCKOUTS: number of Item (product id?) that were reported to be out of stock in the store.\nTAG_BO: Boolean that indicates if the order was labeled as bad order.\nTAG_BO_CANCEL: Indicades if the order was cancelled or not.\n\ndf.tail()\n\n\ndf.info()\n\n\ndf.isnull().sum()\n\n\ndf.describe()\n\n\n2. Exploratory Data Analysis (EDA) (univariate / bivariate analysis)\n\n\nTranslation of the dataset from Spanish to English\n\nDIA_NOMBRE: Keep the name of the days when the order was\n\n\n# Checking unique values\ndf['DIA_NOMBRE'].unique()\n\n\n# Translating the Spanish values\ntrans = {'sábado': 'Saturday', 'lunes':'Monday', 'jueves':'Thursday', 'martes':'Tuesday', 'viernes':'Friday', 'miércoles':'Wednesday',\n       'domingo':'Sunday'}\ndf['DIA_NOMBRE'] = df['DIA_NOMBRE'].map(trans)\n\n\n# Lower case of the columns\ndf.columns = df.columns.str.lower()\n\n\n# Checking the values\ndf['sub_vertical'].unique()\n\nThe variable ‘SUB_VERTICAL’ contains the business sector to which is related the store. In this case, the labels are translated and compacted in fewer classes.\n\n# Translating the Spanish values\ntrans1 = {'Super' : 'Supermarket', 'Floristeria':'E-commerce', 'Express':'Convenient Store', 'Especializada': 'Special Convenient Store', 'Moda':'E-commerce',\n       'Libreria':'E-commerce', 'Tecnologia':'E-commerce', 'Hogar':'E-commerce', 'Farmacia':'Pharmacie', 'Mascotas':'Pet Shop',\n       'Smoking shop':'E-commerce', 'Belleza':'E-commerce', 'Regalos':'E-commerce', 'Licores':'Licours Shop', 'Deportes':'E-commerce',\n       'Bebes y niños':'E-commerce', 'Jugueteria':'E-commerce', 'Sex shop':'E-commerce', 'TurboX':'E-commerce', 'Papeleria':'E-commerce',\n       'Outlet':'E-commerce'}\ndf['sub_vertical'] = df['sub_vertical'].map(trans1)\n\n\ndf = df.rename(columns={'sub_vertical':'store_category','mz_name':'district_name','date_agg':'date','dia_nombre':'weekday','gmv_usd':'order_value_usd','stockouts':'out_of_stock','tag_bo':'bad_order','tag_bo_cancel':'is_canceled' })\n\n\ndf.head()\n\nThe variables ORDER_ID and DATE are being dropped since these data is most useful in traceability than predictibility\n\n# Dropping unecessary columns\ndf.drop(['order_id','date'], axis= 1,inplace= True)\n\nThe data checked present a lot of variables with blank data. The next strategies are going to be implemented on the data:\n\nImputing the mean or mode value for the blank values: For the variables ‘STORE_CATEGORY’,‘VEHICLE_TYPE’ Since, in this categories,the is an actual probability that the values are related to the median or mode.\nDrop rows of the null values: ‘LAT’,‘LNG’,‘POLYGON_SIZE’. The number of rows are low and can be dropped.\nPut the fixed value ‘FALSE’ in ‘USE_CREDIT’: Since this is a boolean variable, and the blanks values mean False\nPut the fixed value of 0: For the variables T04,T05,T06, and rappi_amount because these variabkes are time variables and currency, in which if they don’t have value means that for that field, it doesn’t apply the variable.\nFinally, the variable % completed orders is in varchar and is going to be changed to decimal value\n\n\n# Checking null values\ndf.isnull().sum()\n\n\ndf.info()\n\n\ndf[['vehicle_type', 'store_category', 'distance_km', 'out_of_stock']].info()\n\n\n# Removing % label\ndf['% completed orders user']=df['% completed orders user'].str.replace('%',' ')\n\ndf['% completed orders user']=df['% completed orders user'].astype('float')\ndf['% completed orders user']=df['% completed orders user']/100\n\n\ndf[['% completed orders user']].info()\n\n\n# Remove missing values\ndf.dropna(subset=['lat','lng','vehicle_type'],inplace=True)\n\n\n#Imputing values of mode and mean for the variables\n\nmode_ps = df['polygon_size'].mode()[0]\ndf['polygon_size'].fillna(mode_ps, inplace=True)\n\n\nmean_ic = df['item_count'].mean()\ndf['item_count'].fillna(mean_ic, inplace=True)\n\n\nmode_sc = df['store_category'].mode()[0]\ndf['store_category'].fillna(mode_sc, inplace=True)\n\n\n# Replace missing values\ndf.fillna({'t04_picking_time': 0, 't05_cashier_time': 0, 't06_requesting_rt_time':0, 'rappi_amount':0}, inplace=True)\n\n\n# Replace missing values\ndf.fillna({'use_credit': False},inplace=True)\n\n\nzero_count = (df['order_value_usd'] == 0).sum()\nprint(zero_count)\n\n\n# Check duplicate values\ndup_value = df.duplicated().sum()\nprint(dup_value)\n\n\ndf.isnull().sum()\n\n\ndf.describe()\n\n\ndf.head()\n\n\n# Removing negative values\nnegative_cols = ['user_total_orders', 'item_count', 't04_picking_time', 't05_cashier_time', 't06_requesting_rt_time',\n                 'out_of_stock', 'distance_km', 'hora', 'polygon_size', 'rappi_amount']\n\n# Create a mask that identifies rows with any negative value in the specified columns\nnegative_mask = df[negative_cols].lt(0).any(axis=1)\n\n# Use the mask to filter out rows with negative values\ndf1 = df[~negative_mask]\n\n\n# Separating quantiative & Categorical variables\ndf_cat = df.select_dtypes(include=['object','bool'])\ndf_quan = df.select_dtypes(exclude=['object','bool'])\n\n\n# Create a heatmap\nplt.figure(figsize=(10, 8))\ndf_quan_corr = df_quan.corr(method = 'spearman' )\nax = sns.heatmap(df_quan_corr, annot=True, cmap='coolwarm', center=0,fmt='.2g',xticklabels='auto', yticklabels='auto',linewidth=.8,cbar_kws={\"shrink\": .8})\nax.tick_params(axis='both', which='both', labelsize=8)\nplt.title(\"Correlation Heatmap\")\nplt.show()\n\n\n# Create a pairplot\nsns.pairplot(df_quan)\n\n\nfor col in df_quan.columns:\n    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n\n    # Histogram\n    sns.histplot(df_quan[col], kde=True, bins=20, ax=ax[0])\n    ax[0].set_title(f'Histogram for {col}')\n    ax[0].set_xlabel(col)\n    ax[0].set_ylabel('Frequency')\n\n    # Box plot\n    sns.boxplot(x=df_quan[col], ax=ax[1])\n    ax[1].set_title(f'Boxplot for {col}')\n    ax[1].set_xlabel(col)\n\n    plt.tight_layout()\n    plt.show()\n\n\ndf_quan.columns\n\n\n#Removing outliers for : % completed orders user, picking_time, cashier_time, t_06, polygon size, rapi_amount\ncolumns = ['t04_picking_time', 't05_cashier_time',\n           't06_requesting_rt_time', 'polygon_size', 'rappi_amount']\n\nQ1 = df[columns].quantile(0.25)\nQ3 = df[columns].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\noutliers = pd.DataFrame()\nfor col in columns:\n    condition = (df[col] &lt; lower_bound[col]) | (df[col] &gt; upper_bound[col])\n    outliers = outliers.append(df[condition], ignore_index=True)\n\n\n#chi_squared for categorical\nfrom scipy.stats import chi2_contingency\n\nchi_squared_results = pd.DataFrame(columns=['Variable 1', 'Variable 2', 'Chi-Squared', 'P-Value'])\n\nfor var1 in df_cat:\n    for var2 in df_cat:\n        if var1 != var2:\n          #if var2 =='bad_order':\n            contingency_table = pd.crosstab(df[var1], df[var2])\n\n            chi2, p, _, _ = chi2_contingency(contingency_table)\n\n\n            new_row = pd.DataFrame({'Variable 1': [var1], 'Variable 2': [var2], 'Chi-Squared': [chi2], 'P-Value': [p]})\n\n            chi_squared_results = pd.concat([chi_squared_results, new_row], ignore_index=True)\n\nchi_squared_results\n\n\n#Checking for independance between our outcome bad_order and the categorical variables\n\n\n#chi_squared for categorical\nfrom scipy.stats import chi2_contingency\n\nchi_squared_results = pd.DataFrame(columns=['Variable', 'Chi-Squared', 'P-Value'])\n\noutcome_variable = 'bad_order'\n\nfor var in df_cat:\n        if var != outcome_variable:\n            contingency_table = pd.crosstab(df[outcome_variable], df[var])\n\n            chi2, p, _, _ = chi2_contingency(contingency_table)\n\n\n            new_row = pd.DataFrame({'Variable': var, 'Chi-Squared': [chi2], 'P-Value': [p]})\n\n            chi_squared_results = pd.concat([chi_squared_results, new_row], ignore_index=True)\n\n            if p &lt; 0.05:\n              print(f\"There is a significant association between {outcome_variable} and {var} (p-value = {p:.2f})\")\n            else:\n              print(f\"There is no significant association between {outcome_variable} and {var} (p-value = {p:.2f})\")\n\n#H0 there is no relathionship between the variables\n\nchi_squared_results\n\n\n#Perfoming ANOVA TEST for mixed categorical and numerical values\n\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.anova import anova_lm\n\n# List of numerical variables for the ANOVA tests\ndf_cuantitative = ['% completed orders user', 'order_value_usd', 'item_count', 't04_picking_time', 't05_cashier_time', 't06_requesting_rt_time', 'out_of_stock', 'distance_km', 'hora']\n\n# Perform ANOVA for numerical variables\nfor num_var in df_cuantitative:\n    formula = f'{num_var} ~ C(bad_order)'\n    try:\n        model = ols(formula, data=df).fit()\n        anova_table = anova_lm(model)\n        print(f\"ANOVA table for {num_var} and bad_order:\")\n        print(anova_table)\n\n        p_value = anova_table['PR(&gt;F)'][0]\n        if p_value &lt; 0.05:\n            print(f\"There is a significant difference between the means of the groups defined by bad_order for {num_var} (p-value = {p_value:.2f})\")\n        else:\n            print(f\"There is no difference between the means of k groups\")\n\n        print(\"=\" * 40)\n\n    except Exception as e:\n        print(f\"Error for {num_var} and bad_order: {str(e)}\")\n\n\n\n\n\n\n4. Machine Learning\n\n# Feature engineering\ndf_quan\n\nFor this part we are going to start put the data in a standarization and onehot encoding so the data is ready to be inserted in the modeling. For it, we are going to use the Pipeline method\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass VariableSelector(BaseEstimator, TransformerMixin):\n    def __init__(self,attribute_names):\n        self.attribute_names = attribute_names\n\n    def fit(self, X , y=None):\n        return self\n\n    def transform(self, X):\n        return X[self.attribute_names]\n\n\ncolumns_quan = list(df_quan.columns)\n\n\ncolumns_quan\n\n\n#quantitative\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nquanti_pipeline = Pipeline(\n    [\n     ('selector', VariableSelector(columns_quan)),\n     ('std_scaler', StandardScaler())\n    ]\n    )\n\n\n#It is being checked in the case of the categorical variables, which values can be apprved for a OHE method or label encoding\n\ndf_cat_oh = ['country','payment_method','city','vehicle_type','store_category','use_credit']\ndf_cat_le = ['district_name','brand_group']\n\n\nfrom sklearn.preprocessing import OneHotEncoder as OHE\n\ncuali_pipeline_ohe = Pipeline(\n\n  [\n    ('selector',VariableSelector(df_cat_oh)),\n    ('OHE_columns',OHE(sparse=False))\n\n  ]\n\n)\n\n\nfrom sklearn.preprocessing import OrdinalEncoder as OE\n\ncuali_pipeline_le =Pipeline(\n\n                            [\n                             ('selector',VariableSelector(df_cat_le)),\n                             ('LE_columns', OE())\n                            ]\n\n)\n\n\nfrom sklearn.pipeline import FeatureUnion\n\nfull_pipeline =FeatureUnion(\n    transformer_list=[\n        ('num_pipeline', quanti_pipeline),\n        ('ohe_pipeline',cuali_pipeline_ohe),\n        ('le_pipeline',cuali_pipeline_le)\n                      ]\n)\n\nOnce that is defined the Pipeline, to do the adjustements on the data. It is going to be retrieved from the main dataset the y to be predicted\n\nx_df = full_pipeline.fit_transform(df)\n\n\nX = x_df\ny = df['bad_order']\n\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=42,shuffle=True,stratify = y)\n\nNow that we splited our data, we will apply 3 models on our categorical outcome (Logistic regression, Classification Tree, Random Forest)\n\nLOGISTICS REGRESSION\n\n\n#Logistic Regression Model Fitting\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(penalty = None, solver = 'newton-cholesky')\nlogreg.fit(X_train, y_train)\n\n#Predicting the test set results\nlr_pred = logreg.predict(X_test)\n\n\n#Calculating the accuracy\nprint('Accuracy of Logistic Regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n\n\n#Checking crossvalidated performance\nfrom sklearn.model_selection import cross_val_score\ncv_score = cross_val_score(logreg, X_test, y_test)\nprint(f\"average cross validated score : {np.mean(cv_score)}\")\n\n\n#Logistic Regression model performance with Confusion Matrix\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\nconfusion_matrix_lr = confusion_matrix(y_test, lr_pred, labels= logreg.classes_)\nConfusionMatrixDisplay(confusion_matrix_lr, display_labels = logreg.classes_).plot()\nprint(classification_report(y_test,lr_pred))\n\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score,roc_auc_score,cohen_kappa_score,roc_curve\naccuracy_lr = accuracy_score(y_test, lr_pred)\nprecision_lr = precision_score(y_test, lr_pred)\nsensitivity_lr = recall_score(y_test, lr_pred)\nf1_lr = f1_score(y_test, lr_pred)\n\n#ROC Curve\nlr_pred_prob= logreg.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, lr_pred_prob[:,1])\nlr_roc_auc = roc_auc_score(y_test, lr_pred_prob[:,1])\n\n\nresult_lr = pd.DataFrame([['Log. reg.',accuracy_lr, precision_lr, sensitivity_lr,f1_lr,lr_roc_auc]], columns=('model','accuracy','precision','sensitivity','f1','roc'))\nresult_lr\n\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label=' Logit Regression - ROC curve (area = {:.2f})'.format(lr_roc_auc))\nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\nplt.xlim([0.0, 1])\nplt.ylim([0.0, 1])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc='lower center')\nplt.show()\n\n\nDecision Tree\n\n\n#Classification Tree Model Fitting\n\nfrom sklearn.tree import DecisionTreeClassifier\n# Initializing Decision Tree classifer object\nclf = DecisionTreeClassifier()\n\n# Train Decision Tree Classifer\nclf.fit(X_train,y_train)\n\n#Predicting on the test set\nclf_pred = clf.predict(X_test)\n\n\n#Calculating the model accuracy, how often is the classifier correct ?\nfrom sklearn.metrics import accuracy_score\n\nprint(\"Accuracy Decision Tree Classifier: {:.2f}\".format(accuracy_score(y_test, clf_pred)))\n\n\n#Classification Tree Model performance\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\nconfusion_matrix_clf = confusion_matrix(y_test, clf_pred, labels = clf.classes_)\nConfusionMatrixDisplay(confusion_matrix_clf, display_labels= clf.classes_).plot()\nprint(classification_report(y_test, clf_pred))\n\n\nfrom sklearn.tree import export_graphviz\n\nexport_graphviz(\n clf,\n out_file=(\"order_simple.dot\"),\n feature_names=None,\n class_names=None,\n filled=True,\n)\n\n\n!dot -Tpng hitters_simple.dot -o hitters_simple.png\n\n\nfrom IPython.display import Image\nImage(\"order_simple.png\")\n\n\naccuracy_clf = accuracy_score(y_test, clf_pred)\nprecision_clf = precision_score(y_test, clf_pred)\nsensitivity_clf = recall_score(y_test, clf_pred)\nf1_clf = f1_score(y_test, clf_pred)\n\n\n#ROC Curve\nclf_pred_prob= clf.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, clf_pred_prob[:,1])\nclf_roc_auc = roc_auc_score(y_test, clf_pred_prob[:,1])\n\n\nresult_clf = pd.DataFrame([['decision tree',accuracy_clf, precision_clf, sensitivity_clf,f1_clf,clf_roc_auc]], columns=('model','accuracy','precision','sensitivity','f1','roc'))\nresult_clf\n\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label='Tree Dec. -ROC curve (area = {:.2f})'.format(clf_roc_auc))\nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\nplt.xlim([0.0, 1])\nplt.ylim([0.0, 1])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc='lower center')\nplt.show()\n\n\nRandom Forest\n\n\n#Random Forest Model Fitting\n\nfrom sklearn.ensemble import RandomForestClassifier\n# Initializing Random Forest Classifer object\nrf = RandomForestClassifier()\n\n# Train Random Forest Classifer\nrf.fit(X_train, y_train)\n\n#Predicting on the test set\nrf_pred = rf.predict(X_test)\n\n\n#Calculating Random Forest model accuracy\naccuracy_rf = accuracy_score(y_test, rf_pred)\nprint(\"Accuracy Random Forest Classifier: {:.2f}\".format(accuracy_rf))\n\n\n#Random Forest Classifier model performance\nconfusion_matrix_rf = confusion_matrix(y_test, rf_pred, labels = rf.classes_)\nConfusionMatrixDisplay(confusion_matrix_rf, display_labels= rf.classes_).plot()\nprint(classification_report(y_test, rf_pred))\n\n\naccuracy_rf = accuracy_score(y_test, rf_pred)\nprecision_rf = precision_score(y_test, rf_pred)\nsensitivity_rf = recall_score(y_test, rf_pred)\nf1_rf = f1_score(y_test, rf_pred)\n\n\n#ROC Curve\nrf_pred_prob= rf.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, rf_pred_prob[:,1])\nrf_roc_auc = roc_auc_score(y_test, rf_pred_prob[:,1])\n\nresult_rf = pd.DataFrame([['random forest',accuracy_rf, precision_rf, sensitivity_rf,f1_rf,rf_roc_auc]], columns=('model','accuracy','precision','sensitivity','f1','roc'))\nresult_rf\n\nAfter checking model performance accuracy (counts of correct classification) we can assume that our best model is Random Forest Classifier with 0.93% of correctly predicted predictions\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label='Rand. forest -ROC curve (area = {:.2f})'.format(rf_roc_auc))\nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\nplt.xlim([0.0, 1])\nplt.ylim([0.0, 1])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc='lower center')\nplt.show()\n\n\nresultados = pd.concat([result_lr, result_clf,result_rf], axis=0)\nresultados\n\nResults:\n\nMetrics\n\n\nOverall the accuracy between all the models seems to be high (between 86 and 92%) which meant that the models have been a great deal into predicting if the order was labeled as a good one or bad one.\nPrecision: However, for this exercise it is most interesting to predict only the bad orders, to which this metric is most important. As it can be revised, the random forest model is the one with the best result out of the three. Which means that of the total predicted true bad orders, the model have an 86% of good prediction\nSensitivity: However, all the models had a bad ratio in this metric. This metric indicates that the of all the True orders labeled as bad order, only ;in the best case; was predicted 30% of this cases. To make the model more fit, it will be used the methods for reduce the overfitting of the models.\n\n\n\nTuning model\n\nestimators = list(range(2, 50, 5))\nsens_rf_num_estimators = []\naccu_rf_num_estimators = []\n\nfor n in estimators:\n    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n    rf.fit(X_train, y_train)\n    y_pred = rf.predict(X_test)\n    sensitivity_rf = recall_score(y_test, rf_pred)\n    accuracy_rf = accuracy_score(y_test, rf_pred)\n\n    sens_rf_num_estimators.append(sensitivity_rf)\n    accu_rf_num_estimators.append(accuracy_rf)\n\n\n# Plotting the results\nplt.figure(figsize=(10, 6))\nplt.plot(estimators, sens_rf_num_estimators, marker='o', linestyle='-', color='b')\nplt.plot(estimators,accu_rf_num_estimators, marker='x', linestyle='-', color='r')\nplt.title('Sensitivity vs. Number of Estimators')\nplt.xlabel('Number of Estimators')\nplt.ylabel('%')\nplt.grid(True)\nplt.show()\n\n\ntrain_scores = []\nvalid_scores = []\nleaves = list(range(2,30))\nfor leaf in leaves :\n    dtr = RandomForestClassifier(min_samples_leaf = leaf)\n    dtr.fit(X_train, y_train)\n    train_scores.append(dtr.score(X_train, y_train))\n    valid_scores.append(dtr.score(X_test, y_test))\n\nplt.figure(figsize=(10,8))\nplt.plot(leaves, train_scores)\nplt.plot(leaves, valid_scores)\nplt.xlabel(\"minimum samples per leaf\")\nplt.ylabel(\"score values\")\nplt.legend([\"training scores\", \"validation scores\"])\nplt.show()\n\n\ntrain_scores = []\nvalid_scores = []\ndepths = list(range(2,40))\nfor depth in depths :\n    dtr = RandomForestClassifier(max_depth = depth)\n    dtr.fit(X_train, y_train)\n    train_scores.append(dtr.score(X_train, y_train))\n    valid_scores.append(dtr.score(X_test, y_test))\n\nplt.figure(figsize=(10,8))\nplt.plot(depths, train_scores)\nplt.plot(depths, valid_scores)\nplt.xlabel(\"maximum depth\")\nplt.ylabel(\"score values\")\nplt.legend([\"training scores\", \"validation scores\"])\nplt.show()\n\n\nGridSearchCV\n\n\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {'max_depth': list(range(2, 15)), 'min_samples_leaf': list(range(2,20))}\n\ngrid_search_cv = GridSearchCV(RandomForestClassifier(),\n                              params,\n                              verbose=1,\n                              cv=3,\n                              n_jobs=-1)\n\ngrid_search_cv.fit(X_train, y_train)\n\n\nbest_tree_model = grid_search_cv.best_estimator_\nbest_tree_model\n\n\nbest_tree_model.fit(X_train,y_train)\nbest_tree_model.score(X_test,y_test)\n\n\nrfo_pred = best_tree_model.predict(X_test)\n\n\nfrom sklearn.tree import export_graphviz\ntree_to_visualize = best_tree_model.estimators_[0]\n\nexport_graphviz(\n    tree_to_visualize,\n    out_file=(\"optimal_tree.dot\"),\n    feature_names=None,  # Specify your feature names if needed\n    class_names=None,    # Specify class names for classification tasks\n    filled=True\n)\n\n\n!dot -Tpng hitters_simple.dot -o hitters_simple.png\nImage(\"optimal_tree.png\")\n\n\naccuracy_rfo = accuracy_score(y_test, rfo_pred)\nprecision_rfo = precision_score(y_test, rfo_pred)\nsensitivity_rfo = recall_score(y_test, rfo_pred)\nf1_rfo = f1_score(y_test, rfo_pred)\n\n\nresult_rfo = pd.DataFrame([['optimal random forest',accuracy_rfo, precision_rfo, sensitivity_rfo,f1_rfo]], columns=('model','accuracy','precision','sensitivity','f1'))\nresult_rfo\n\n\n\nUnsupervised Learning\n\n'''Importing the needed libraries and getting a basic idea on the df_quant to see what we are looking at'''\ntry:\n    from fanalysis.pca import PCA\nexcept:\n    !pip install fanalysis\n    from fanalysis.pca import PCA\ndisplay(df[df_quan].head(3))\ndisplay(df[df_quan].info())\np = D.shape[1]\nn = D.shape[0]\nD = df[df_quan]\nX = D.values\n\n\n'''Step 1: Try PCA to reduce dimensionality'''\n# instantiate acp object form PCA class\nacp = PCA(std_unit=True,row_labels=D.index,col_labels=D.columns) #std_unit=True, doing standardized PCA)\n\n# run PCA on X observed data\ntry:\n    acp.fit(X)  # This will raise a ZeroDivisionError\nexcept Exception as e:\n    display(f\"An error occurred: {e}\")\n\n\n'''Step 2: Trouble shooting the error, which may indicate that there are columns that are zero'''\nD_corr = D.corr()\nax = sns.heatmap(D_corr, annot=True, cmap='coolwarm', center=0,fmt='.2g',xticklabels='auto', yticklabels='auto',linewidth=.8,cbar_kws={\"shrink\": .8})\nax.tick_params(axis='both', which='both', labelsize=8)\nplt.title(\"Correlation Heatmap\")\nplt.show()\n\n\n'''\nStep 3: Issue becomes clear that the 't06_requesting_rt_time' is the problematic one because apparently\nafter data cleaning, all the values we kept are zero, which makes sense given the value means the time it took for\na delivery personnel to be assigned to the order, which is expected to be swifty in any delivery app.\n\nSolution here: get rid off such column and do it again\n'''\ndisplay(D.columns[5])\nD1 = D.drop(columns = [D.columns[5]])\nX1 = D1.values\np1 = D1.shape[1]\nn1 = D1.shape[0]\nacp = PCA(std_unit=True,row_labels=D1.index,col_labels=D1.columns) #std_unit=True, doing standardized PCA)\nacp.fit(X1)  # This will raise a ZeroDivisionError\ndisplay(acp.col_labels)\ndisplay(acp.eig_) # each lamda k is in the first array, and then each lamda k divided by the sum of lamda k\n#(proportion of variance explained by k),\n# aka the variance explained by each component, is in the second row.\n# The third row is the cumulative variance.\n'''Looking at the cumulative variance, the most variable with the most variance only took 22%\nof the total variance in the quantitative columns'''\ndisplay(acp.eig_.shape)\n\n\n'''Step 4: determining the threshold'''\n\n# first the main plot\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\nax[0].plot(range(1,p1+1),acp.eig_[0],\".-\")\nax[0].set_xlabel(\"Nb. of factors\")\nax[0].set_ylabel(\"Eigenvalues\")\nax[0].set_title(\"Scree Plot\")\n\n# add Kaiser's threshold line\nax[0].plot([1,p1+3],[1,1],\"r--\",linewidth=1)\n\n# print explained variance plot\n\n\nax[1].plot(range(0,p1+1),np.append(0,acp.eig_[2]),\".-\")\nax[1].set_xlabel(\"Nb. of factors\")\nax[1].set_ylabel(\"% of explained variance\")\nax[1].set_title(\"Explained Variance\")\n\n'''According to the plot, I decided to choose 4 as the threshold'''\n\n\n# Applying Barlett's test of Sphericity\ntry:\n    from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nexcept:\n    !pip install factor_analyzer\n    from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n\nchi_square_value, p_value = calculate_bartlett_sphericity(X1)\nprint(chi_square_value, p_value)\n\n\n# Computing Karlis-Saporta-Spinaki threshold\n# impor math package\nimport math\n\n#seuil de Karlis-Saporta-Spinaki\nkss = 1+2*math.sqrt((p1-1)/(n1-1))\nprint(f\"Karlis-Saporta-Spinaki threshold: {kss:.3f}\")\n\n\n# Broken sticks method\n# threshold for the broken sticks\nb = np.flip(np.cumsum(1/np.arange(p1,0,-1)))\nprint(f\"thresholds for the broken sticks: {b}\")\n\n# plot eigenvalues\nfig, ax = plt.subplots(figsize=(5,5))\nax.plot(range(1,p1+1),acp.eig_[0],\".-\")\nax.set_xlabel(\"Nb. if factors\")\nax.set_ylabel(\"Eigenvalues\")\nplt.title(\"Eigenvalues and broken sticks thresholds\")\n\n# add broken sticks thresholds\nax.plot(range(1,p1+1),b,\"r--\",linewidth=1)\n\nplt.show()\n\n\n'''Step 5: Variable representation'''\nprint(pd.DataFrame(acp.col_coord_[:,:4],index=D1.columns, columns=['F1','F2','F3','F4']))\n\n\n# Correlations circle\nacp.correlation_circle(num_x_axis=1,num_y_axis=2, figsize=(5,5))\nacp.correlation_circle(num_x_axis=3,num_y_axis=4, figsize=(5,5))\n'''Interpretation of the two dimensions'''\n'''Three variables have a quite negative correlation with Dim 1, which are item_count, picking_time\nand cashier_time. This means the speed the store can get those orders ready, which, unsurprisingly, also partially\ncomes down to the size of the order. There is clearly a size effect in this dimension'''\n'''Two variables have a quite negative correlation with Dim 2, which are distance_km and order_value_USD. This means\nthat whether the order is cheap and within a shorter distance, most likely being some everyday shopping needs versus\nsome more expensive order traveling a longer distance. This shows a shape effect while Dim 1 shows a size effect'''\n'''Two variables have a quite strong positive correlation with Dim 3, namely 'hora' which means hour, meaning the\ntime in the day, and 'out_of_stock'. This indicates that this axis talks about a general time variation, since the\nearly an order is placed, the less likely that the specific item a customer wants would be sold out.'''\n'''The fourth dimension has a very high correlation on '% completed orders user' which could just be interpreted as\nthat specific variable.'''\n\n\n# Cos² if the variables on the two first factors\nprint(pd.DataFrame(acp.col_cos2_[:,:4],index=D1.columns, columns=['F1','F2','F3','F4']))\n\n\n# Cumulated Cos² on the two first factors\nprint(pd.DataFrame(np.cumsum(acp.col_cos2_[:,:4],axis=1),index=D1.columns, columns=['F1','F2',\"F3\",'F4']))\n\n\n# Contributions of each variable on the two first factors (in %)\nprint(pd.DataFrame(acp.col_contrib_[:,:4],index=D1.columns, columns=['F1','F2',\"F3\",'F4']))\n\n\n# chart of the individuals\nacp.mapping_row(num_x_axis=1,num_y_axis=2,figsize=(7,7))\n\n\n# chart of the individuals\nacp.mapping_row(num_x_axis=3,num_y_axis=4,figsize=(7,7))\n'''From this factor map, we can see clearly that if we use Dim 3 and Dim 4 as our x1 and x2 axis and plot the data\npoints, there is a CLEAR tendency that different clusters are formed likely due to the variance introduced by\ndifferent rows, aka different groups of the customers behaving differently'''\n\n\n# creating a new data frame with the row coordinates of F1, F2, F3 and F4\ndf_row_coord = pd.DataFrame(np.cumsum(acp.row_coord_[:,:4],axis=1),index=D1.index, columns=['F1','F2','F3',\"F4\"])\ndf_row_coord.head(5)\n\n\nmask = df_row_coord['F1'] == df_row_coord['F1'].min()\ndf_row_coord.loc[df_row_coord[mask].index, :]\n\n\n'''Clustering'''\n'''Plotting them one axis by another first'''\nsns.pairplot(df_row_coord)\n\n\n'''Looking at the pairplot between four different dimensions, the pattern is obvious that in some of these pairs\nof features, two different cluster can be seen.'''\n\n\n#Import the library and initialization\nfrom sklearn.cluster import KMeans\n\nX = df_row_coord.values\nkm = KMeans(n_clusters = 2, init = 'k-means++' , n_init = 10, max_iter = 300, random_state = 0, tol = 0.0001)\ny_km = km.fit_predict(X)\n\n\nkm.labels_\nfrom collections import Counter\nunique_counts = Counter(km.labels_)\ndisplay(unique_counts)\n\n\n#Added the clustering info to the dataframe, but it won't affect the original X since X was done in the front as\n#X = df_row_coord.values\ndf_row_coord['Y_KMean'] = y_km\nsns.pairplot(df_row_coord, hue='Y_KMean')\n\n\nfrom sklearn.cluster import DBSCAN\neps_list = [0.2, 0.5, 1, 2, 2.2, 2.5, 2.7, 3, 4, 5]\nfor eps_ in eps_list:\n    DBSCAN_model = DBSCAN(eps = eps_, min_samples=5, metric='euclidean')\n    DBSCAN_model.fit_predict(X)\n    y_DBSCAN = DBSCAN_model.labels_\n    df_row_coord['Y_DBSCAN'] = y_DBSCAN\n    display(df_row_coord['Y_DBSCAN'].value_counts())\n    sns.pairplot(df_row_coord.drop(columns = ['Y_KMean']), hue='Y_DBSCAN')\n\n\nDBSCAN_model = DBSCAN(eps=4, min_samples=5, metric='euclidean')\nDBSCAN_model.fit_predict(X)\ny_DBSCAN = DBSCAN_model.labels_\ndf_row_coord['Y_DBSCAN'] = y_DBSCAN\ndisplay(df_row_coord['Y_DBSCAN'].value_counts())\nsns.pairplot(df_row_coord.drop(columns = ['Y_KMean']), hue='Y_DBSCAN')\n\n\ndf[df_row_coord['Y_DBSCAN'] == 1]\n\n\ndf_row_coord['Y_DBSCAN'].value_counts()"
  },
  {
    "objectID": "posts/ml/index.html",
    "href": "posts/ml/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]